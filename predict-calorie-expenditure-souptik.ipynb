{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91716,"databundleVersionId":11893428,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport joblib","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/playground-series-s5e5/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/playground-series-s5e5/test.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Dataset Shape: {train_df.shape}\")\n\nprint(\"\\nData Info:\")\ntrain_df.info()\n\nprint(\"\\nNumerical Features Summary:\")\ndisplay(train_df.describe())\n\nprint(\"\\nFirst 10 Rows of the Dataset:\")\ndisplay(train_df.head(10))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Dataset Overview:**\n\n* Shape: 750,000 rows, 9 columns.\n* Features:\n* id: Unique identifier (int64, likely not useful for modeling).\n* Sex: Categorical (object, male/female).\n* Age: Numerical (int64, range: 20-79).\n* Height: Numerical (float64, range: 126-222 cm).\n* Weight: Numerical (float64, range: 36-132 kg).\n* Duration: Numerical (float64, range: 1-30 minutes, likely exercise duration).\n* Heart_Rate: Numerical (float64, range: 67-128 bpm).\n* Body_Temp: Numerical (float64, range: 37.1-41.5°C).\n* Target: Calories (float64, range: 1-314 kcal, mean: 88.28).\n* Data Types: 6 float64, 2 int64, 1 object (Sex).\n* Missing Values: None (all columns have 750,000 non-null entries).","metadata":{}},{"cell_type":"markdown","source":"## Let's get some plots:","metadata":{}},{"cell_type":"code","source":"sns.set_style(\"whitegrid\")\nplt.rcParams['font.size'] = 12\nplt.rcParams['axes.titlesize'] = 14\nplt.rcParams['axes.labelsize'] = 12\nplt.rcParams['xtick.labelsize'] = 10\nplt.rcParams['ytick.labelsize'] = 10\nplt.rcParams['legend.fontsize'] = 10\npalette = sns.color_palette(\"coolwarm\", as_cmap=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop 'id' as it's not useful for EDA\ntrain_df = train_df.drop('id', axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define numerical and categorical columns\nnum_cols = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']\ncat_cols = ['Sex']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Distribution Histograms for Numerical Features\nplt.figure(figsize=(15, 10))\nfor i, col in enumerate(num_cols, 1):\n    plt.subplot(3, 3, i)\n    sns.histplot(train_df[col], kde=True, color='dodgerblue', bins=30)\n    plt.title(f'Distribution of {col}', fontweight='bold')\n    plt.xlabel(col)\n    plt.ylabel('Count')\nplt.tight_layout()\nplt.savefig('numerical_distributions.png')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Count Plot for Sex\nplt.figure(figsize=(6, 4))\nsns.countplot(x='Sex', data=train_df, palette='coolwarm')\nplt.title('Distribution of Sex', fontweight='bold')\nplt.xlabel('Sex')\nplt.ylabel('Count')\nplt.savefig('sex_distribution.png')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Correlation Heatmap\nplt.figure(figsize=(10, 8))\ncorr_matrix = train_df[num_cols].corr()\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True, cbar_kws={'label': 'Correlation'})\nplt.title('Correlation Heatmap of Numerical Features', fontweight='bold')\nplt.savefig('correlation_heatmap.png')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Box Plots for Outlier Detection\nplt.figure(figsize=(15, 5))\nfor i, col in enumerate(['Calories', 'Heart_Rate', 'Duration'], 1):\n    plt.subplot(1, 3, i)\n    sns.boxplot(y=train_df[col], color='lightcoral')\n    plt.title(f'Box Plot of {col}', fontweight='bold')\n    plt.ylabel(col)\nplt.tight_layout()\nplt.savefig('box_plots.png')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Scatter Plots (Calories vs. Key Features)\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nsns.scatterplot(x='Duration', y='Calories', hue='Sex', size='Heart_Rate', data=train_df, palette='coolwarm', alpha=0.6)\nplt.title('Calories vs. Duration', fontweight='bold')\nplt.subplot(1, 2, 2)\nsns.scatterplot(x='Heart_Rate', y='Calories', hue='Sex', size='Duration', data=train_df, palette='coolwarm', alpha=0.6)\nplt.title('Calories vs. Heart Rate', fontweight='bold')\nplt.tight_layout()\nplt.savefig('scatter_plots.png')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Pair Plot (Subset of Features)\nsubset_cols = ['Calories', 'Duration', 'Heart_Rate', 'Weight']\nsns.pairplot(train_df[subset_cols], diag_kind='kde', plot_kws={'alpha': 0.5, 'color': 'dodgerblue'})\nplt.suptitle('Pair Plot of Key Features', fontweight='bold', y=1.02)\nplt.savefig('pair_plot.png')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import plotly.express as px\n\n# 7. Interactive Plotly Scatter Plot\nfig = px.scatter(\n    train_df,\n    x='Duration',\n    y='Calories',\n    color='Sex',\n    size='Heart_Rate',\n    hover_data=['Age', 'Weight', 'Body_Temp'],\n    title='Calories vs. Duration by Sex and Heart Rate',\n    color_discrete_map={'male': '#1f77b4', 'female': '#ff7f0e'},  # Professional colors (blue, orange)\n    opacity=0.6,\n    size_max=15  # Control max bubble size for clarity\n)\n\n# Customizing layout for professional look\nfig.update_layout(\n    title_font=dict(size=18, family='Arial', weight='bold'),\n    xaxis_title='Duration (minutes)',\n    yaxis_title='Calories (kcal)',\n    font=dict(family='Arial', size=12),\n    showlegend=True,\n    plot_bgcolor='white',\n    paper_bgcolor='white',\n    xaxis=dict(showgrid=True, gridcolor='lightgray'),\n    yaxis=dict(showgrid=True, gridcolor='lightgray'),\n    legend_title='Sex'\n)\n\n# Adding hover template for better readability\nfig.update_traces(\n    hovertemplate=(\n        '<b>Duration</b>: %{x} min<br>' +\n        '<b>Calories</b>: %{y} kcal<br>' +\n        '<b>Sex</b>: %{customdata[0]}<br>' +\n        '<b>Age</b>: %{customdata[1]}<br>' +\n        '<b>Weight</b>: %{customdata[2]} kg<br>' +\n        '<b>Body Temp</b>: %{customdata[3]} °C<br>' +\n        '<b>Heart Rate</b>: %{marker.size} bpm'\n    ),\n    customdata=train_df[['Sex', 'Age', 'Weight', 'Body_Temp']].values\n)\n\n# Saving it as HTML and display\nfig.write_html('interactive_scatter.html')\nfig.show()\n\nprint(\"Interactive scatter plot saved as 'interactive_scatter.html'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print summary insights\nprint(\"\\nEDA Insights:\")\nprint(\"- Numerical features: Most distributions are slightly skewed (e.g., Calories, Duration).\")\nprint(\"- Sex distribution: Check balance; may influence calorie burn.\")\nprint(\"- Correlations: Duration, Heart_Rate likely strong predictors of Calories.\")\nprint(\"- Outliers: Calories, Heart_Rate show potential outliers; consider capping.\")\nprint(\"- Relationships: Scatter plots suggest linear trends between Calories and Duration/Heart_Rate.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Let's get to modelling:","metadata":{"execution":{"iopub.status.busy":"2025-05-01T15:15:22.445214Z","iopub.execute_input":"2025-05-01T15:15:22.445577Z","iopub.status.idle":"2025-05-01T15:15:22.449826Z","shell.execute_reply.started":"2025-05-01T15:15:22.445552Z","shell.execute_reply":"2025-05-01T15:15:22.448827Z"}}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n\n# Verify input columns\nrequired_cols = ['Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\nfor df, name in [(train_df, 'train'), (test_df, 'test')]:\n    missing = [col for col in required_cols if col not in df.columns]\n    if missing:\n        raise ValueError(f\"Missing columns in {name}_df: {missing}\")\nprint(\"Input columns verified.\")\n\n# Encode Sex\ntrain_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\ntest_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1}).astype('int64')\n\n# Handling Outliers based on realistic figures\ntrain_df['Heart_Rate'] = train_df['Heart_Rate'].clip(50, 200)\ntrain_df['Calories'] = train_df['Calories'].clip(0, 500)\ntrain_df['Body_Temp'] = train_df['Body_Temp'].clip(36, 42)\ntrain_df['Duration'] = train_df['Duration'].clip(0, 60)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Feature Engineering\nfor df in [train_df, test_df]:\n    # Physical Features\n    df['BMI'] = df['Weight'] / (df['Height'].clip(lower=1) / 100) ** 2\n    df['BMR'] = np.where(\n        df['Sex'] == 0,  # Male\n        10 * df['Weight'] + 6.25 * df['Height'] - 5 * df['Age'] + 5,\n        10 * df['Weight'] + 6.25 * df['Height'] - 5 * df['Age'] - 161  # Female\n    )\n    # Exercise Intensity\n    df['Intensity'] = df['Duration'] * df['Heart_Rate']\n    df['METs'] = df['Heart_Rate'] / 10\n    # Health Features\n    df['Temp_Anomaly'] = df['Body_Temp'] - 37\n    df['Age_Group'] = pd.cut(\n        df['Age'],\n        bins=[20, 30, 40, 50, 60, 80],\n        labels=['20-30', '31-40', '41-50', '51-60', '61-80'],\n        include_lowest=True\n    )\n    # Physics-Based Feature (Keytel Equation)\n    df['Keytel_Estimate'] = (\n        (0.6309 * df['Heart_Rate'] + 0.1988 * df['Weight'] + 0.2017 * df['Age'] - 55.0969) *\n        df['Duration'] / 4.184\n    )\n    # New Interaction Features\n    df['HR_Duration'] = df['Heart_Rate'] * df['Duration']\n    df['Weight_BMI'] = df['Weight'] * df['BMI']\n    df['METs_Duration'] = df['METs'] * df['Duration']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify engineered columns\nengineered_cols = ['BMI', 'BMR', 'Intensity', 'METs', 'Temp_Anomaly', 'HR_Duration', 'Weight_BMI', 'METs_Duration']\nfor df, name in [(train_df, 'train'), (test_df, 'test')]:\n    missing = [col for col in engineered_cols if col not in df.columns]\n    if missing:\n        raise ValueError(f\"Engineered columns missing in {name}_df: {missing}\")\n\nprint(\"Train columns after feature engineering:\", train_df.columns.tolist())\nprint(\"Test columns after feature engineering:\", test_df.columns.tolist())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encode Age_Group (one-hot encoding)\ntrain_df = pd.get_dummies(train_df, columns=['Age_Group'], drop_first=True)\ntest_df = pd.get_dummies(test_df, columns=['Age_Group'], drop_first=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"expected_cols = train_df.columns.drop('Calories')\nmissing_cols = [col for col in expected_cols if col not in test_df.columns]\nif missing_cols:\n    for col in missing_cols:\n        test_df[col] = 0\ntest_df = test_df[expected_cols]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify column alignment\nprint(\"\\nTrain columns (excl. Calories):\", expected_cols.tolist())\nprint(\"Test columns:\", test_df.columns.tolist())\nif not test_df.columns.tolist() == expected_cols.tolist():\n    raise ValueError(\"Test columns do not match train columns.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Scale Numerical Features\nscaler = StandardScaler()\nnum_cols = [\n    'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp',\n    'BMI', 'BMR', 'Intensity', 'METs', 'Temp_Anomaly', 'HR_Duration',\n    'Weight_BMI', 'METs_Duration'\n]\n\nfor df, name in [(train_df, 'train'), (test_df, 'test')]:\n    missing = [col for col in num_cols if col not in df.columns]\n    if missing:\n        raise ValueError(f\"Scaling columns missing in {name}_df: {missing}\")\n\ntrain_df[num_cols] = scaler.fit_transform(train_df[num_cols])\ntest_df[num_cols] = scaler.transform(test_df[num_cols])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Polynomial Features for Age and Heart_Rate\npoly = PolynomialFeatures(degree=2, include_bias=False)\npoly_cols = ['Age', 'Heart_Rate']\n\ntrain_poly = pd.DataFrame(poly.fit_transform(train_df[poly_cols]), columns=[f'poly_{c}' for c in poly.get_feature_names_out(poly_cols)])\ntest_poly = pd.DataFrame(poly.transform(test_df[poly_cols]), columns=[f'poly_{c}' for c in poly.get_feature_names_out(poly_cols)])\n\ntrain_df = pd.concat([train_df.drop(poly_cols, axis=1), train_poly], axis=1)\ntest_df = pd.concat([test_df.drop(poly_cols, axis=1), test_poly], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure all columns are numerical\nfor df in [train_df, test_df]:\n    for col in df.columns:\n        if col != 'Calories':\n            df[col] = df[col].astype('float64')\n\n# Verify dtypes\nprint(\"\\nTrain dtypes:\\n\", train_df.dtypes)\nprint(\"\\nTest dtypes:\\n\", test_df.dtypes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify no missing values\nprint(\"\\nTrain Missing Values:\\n\", train_df.isnull().sum())\nprint(\"\\nTest Missing Values:\\n\", test_df.isnull().sum())\n\n# Display shapes\nprint(f\"\\nTrain Shape: {train_df.shape}\")\nprint(f\"Test Shape: {test_df.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save preprocessed data\ntrain_df.to_csv('preprocessed_train.csv', index=False)\ntest_df.to_csv('preprocessed_test.csv', index=False)\njoblib.dump(scaler, 'scaler.pkl')\n\nprint(\"Preprocessed data and scaler saved.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Let's get regressor working:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom xgboost import XGBRegressor\nimport joblib\nimport shap\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport optuna","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load preprocessed data\ntrain_df = pd.read_csv('preprocessed_train.csv')\ntest_df = pd.read_csv('preprocessed_test.csv')\n\n# Load test IDs\ntest_ids = pd.read_csv(\"/kaggle/input/playground-series-s5e5/test.csv\")['id']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom xgboost import XGBRegressor","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split features and target\nX = train_df.drop('Calories', axis=1)\ny = train_df['Calories']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# XGBoost with Optuna Tuning\ndef objective(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0)\n    }\n    model = XGBRegressor(**params, random_state=42)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_val)\n    return mean_squared_error(y_val, y_pred)\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=50)\nbest_params = study.best_params\nprint(\"Best XGBoost Parameters:\", best_params)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train XGBoost with best parameters\nxgb_model = XGBRegressor(**best_params, random_state=42)\nxgb_model.fit(X_train, y_train)\ny_pred_xgb = xgb_model.predict(X_val)\nxgb_mse = mean_squared_error(y_val, y_pred_xgb)\nxgb_mae = mean_absolute_error(y_val, y_pred_xgb)\nxgb_r2 = r2_score(y_val, y_pred_xgb)\n\nprint(f\"XGBoost - MSE: {xgb_mse:.2f}, MAE: {xgb_mae:.2f}, R²: {xgb_r2:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nfrom sklearn.model_selection import cross_val_score\n\n# Cross-Validation to Check Overfitting\nxgb_model = XGBRegressor(**best_params, random_state=42, n_jobs=-1)\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\ncv_mse = -cross_val_score(xgb_model, X, y, cv=kf, scoring='neg_mean_squared_error')\ncv_mae = -cross_val_score(xgb_model, X, y, cv=kf, scoring='neg_mean_absolute_error')\ncv_r2 = cross_val_score(xgb_model, X, y, cv=kf, scoring='r2')\n\nprint(\"\\n5-Fold Cross-Validation Metrics:\")\nprint(f\"MSE: {cv_mse.mean():.2f} (+/- {cv_mse.std() * 2:.2f})\")\nprint(f\"MAE: {cv_mae.mean():.2f} (+/- {cv_mae.std() * 2:.2f})\")\nprint(f\"R²: {cv_r2.mean():.2f} (+/- {cv_r2.std() * 2:.2f})\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train final model on full training data\nxgb_model.fit(X, y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Validate on hold-out set (for reference)\ny_pred_val = xgb_model.predict(X_val)\nmse = mean_squared_error(y_val, y_pred_val)\nmae = mean_absolute_error(y_val, y_pred_val)\nr2 = r2_score(y_val, y_pred_val)\nprint(f\"\\nValidation Metrics (Hold-Out):\")\nprint(f\"MSE: {mse:.2f}\")\nprint(f\"MAE: {mae:.2f}\")\nprint(f\"R²: {r2:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Residual Plot to Inspect Errors\nplt.figure(figsize=(8, 6))\nsns.scatterplot(x=y_val, y=y_val - y_pred_val)\nplt.axhline(0, color='red', linestyle='--')\nplt.xlabel('Actual Calories (kcal)')\nplt.ylabel('Residuals')\nplt.title('Residual Plot', fontweight='bold')\nplt.savefig('residual_plot.png')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict on test set\ntest_predictions = xgb_model.predict(test_df)\n\n# Clip predictions to reasonable range (based on train data)\ntest_predictions = np.clip(test_predictions, 0, 500)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# SHAP Feature Importance\nexplainer = shap.TreeExplainer(xgb_model)\nshap_values = explainer.shap_values(X_val)\nshap.summary_plot(shap_values, X_val, plot_type=\"bar\", show=False)\nplt.title('SHAP Feature Importance', fontweight='bold')\nplt.savefig('shap_feature_importance.png')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({'id': test_ids, 'Calories': test_predictions})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nSubmission file created: 'submission.csv'\")\nsubmission.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}